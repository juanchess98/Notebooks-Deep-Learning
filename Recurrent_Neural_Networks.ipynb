{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmEv0ayiW68+EJ0VKc+yKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanchess98/Notebooks-Deep-Learning/blob/Recurrent-Neural-Network/Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neuronales Recurrentes - Recurrent Neural Networks (RNN's)\n",
        "Una red neuronal recurrente se parece mucho a una red neuronal convencional con la excepción de que también tiene conexiones apuntando hacia atrás.\n",
        "La RNN más simple está compuesta de una neurona que recibe entradas y produce una salida y envía la salida de vuelta a si misma. En cada time step $t$   (también llamado frame), esta neurona recurrente recibe las entradas $\\mathbf{x}_{(t)}$ así como su propio output del time step anterior, $\\mathbf{y}_{(t-1)}$.\n",
        "Ya que no hay un output anterior en el primer time step, este se asigna generalmente el valor de 0. Esta pequeña red se puede representar contra el eje del tiempo. Esto se conoce como desenrrollar la red en el tiempo(unrolling the network through time).\n",
        "![RNN](https://drive.google.com/uc?id=1zOI-isp2DN-42ZFjtBKK1XFXDkSi3FiM)\n",
        "\n",
        "Tu puedes crear facilmente un layer de neuronas recurrentes. En cada time step $t$, cada neurona recibe el vector de entrada $\\mathbf{x}_{(t)}$ y el output del vector del time step anterior $\\mathbf{y}_{(t-1)}$. Note que las entradas y las salidas son vector ! \n",
        "\n",
        "Cada neurona recurrente tiene dos pesos. Uno para las entradas $\\mathbf{x}_{(t)}$ y otro para las salidas del time step anterior $\\mathbf{y}_{(t-1)}$ denotados como las matrices $\\mathbf{W}_{x}$ y $\\mathbf{W}_{y}$ respectivamente.\n",
        "\n",
        "La salida de una capa recurrente para una sola instancia está dada así:\n",
        "$$\\mathbf{y}_{(t)} = \\phi(\\mathbf{W}_{x}^{T}\\mathbf{x}_{(t)} +\\mathbf{W}_{y}^{T}\\mathbf{y}_{(t-1)} + \\mathbf{b})$$\n",
        "$\\mathbf{b}$ es el vector bias y $\\phi(.)$ es la función de activación(ReLu o tanh son las más utilizadas).\n",
        "\n",
        "Asi como en las redes neuronales vistas anteriormente, se puede computar la salida de una capa de una capa recurrente de una sola vez al colocar todas las entradas en el time step t en una matriz de entrada $\\mathbf{X}_{(t)}$ así:\n",
        "\n",
        "$$\\mathbf{Y}_{(t)} = \\phi(\\mathbf{W}_{x}^{T}\\mathbf{X}_{(t)} +\\mathbf{W}_{y}^{T}\\mathbf{Y}_{(t-1)} + \\mathbf{b})$$\n",
        "\n"
      ],
      "metadata": {
        "id": "PVni8fTJTUv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory Cells\n",
        "\n",
        "Ya que la salida de una neurona recurrente en cada time step es una función de todas las entradas de los time step anteriores se podría decir que tiene una forma de memoria. Una parte de una red neuronal que preserva algún tipo de estado a lo largo de los time steps es llamada una memory cell(o simplemente una cell). A una simple neurona recurrente o una capa de neuronas recurrentes es una cell muy básica, capaz de de aprender patrones cortos(tipicamente de un largo de 10 steps, pero varía de acuerdo a la tarea).\n",
        "\n",
        "De manera general, el estado de una celda en el time step $t$, denotado como $\\mathbf{h}_{(t)}$(la \"h\" es por \"hidden\"), es una función de algunas entradas en ese time step y de su estado en el time step anterior: $\\mathbf{h}_{(t)} = f(\\mathbf{h}_{(t-)}, \\mathbf{x}_{(t)})$. Su salida en el time step $t$, denotada como $\\mathbf{y}_{(t)}$ es también una función del estado previo y las entradas del time step actuales. En el caso las celdas básicas que hemos discutido hasta ahora la salida es simplemente igual al estado, pero en celdas más complejas este no es siempre el caso. La salida en este caso es: $\\mathbf{Y}_{(t)} = \\mathbf{W}_{ht}\\mathbf{h}_{(t)}$ una matriz de pesos que multiplica al estado actual. \n",
        "\n",
        "![RNN with output different](https://drive.google.com/uc?id=1dGUf3itlQnss6TkQ3sR9W6q-1oDtoZDY)\n"
      ],
      "metadata": {
        "id": "PkLYU_JqjimG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secuencias de Entrada y Salida\n",
        "\n",
        "Una RNN toma una secuencia de entrada y la convierte en una secuencia de salida. Este tipo de red llamada sequence-to-sequence es útil para predecir series de tiempo tal  como stock prices.\n",
        "\n",
        "Alternativamente, tu podrías ignorar todas las salidas excepto la última. En otras palabras, esto es una sequence-to-vector network. Por ejemplo, tu podrías alimentar la red con una sequencia de palabras correspondientes a la opinión sobre una pelicula y la salida de la red seria un puntaje de sentimiento(de -1[hate] hasta +1[love]).\n",
        "\n",
        "Contrariamente, tu puedes darle a la red el mismo vector de entrada una y otra vez en cada time step y dejas como salida una sequencia. Este tipo de red se denomina vector-to-sequence. Un ejemplo de esto podría ser una imagen(o la salida de una CNN) a la entrada de la red y la salida podría ser una descripción de esa imagen.\n",
        "\n",
        "Por último, tu podrías tener una red sequence-to-vector llamada encoder, seguido de una red vector-to-sequence llamada decoder. Por ejemplo, esto podría ser utilizado para traducir una oración de un lenguaje a otro \n",
        "![Types of Networks](https://drive.google.com/uc?id=1R34_wnKdzhfflNbBe9cVkf2cAmy3p_eh)\n"
      ],
      "metadata": {
        "id": "MOoKLkkmXHEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kwhtyTjBN6Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "eUpeTMxYCqDP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_time_series(batch_size, n_steps):\n",
        "  freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
        "  time = np.linspace(0, 1, n_steps)\n",
        "  series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n",
        "  series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
        "  series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n",
        "  return series[..., np.newaxis].astype(np.float32)"
      ],
      "metadata": {
        "id": "bADESd4cCo89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función crea cuantas series de tiempo como sea requerido(a través del batch_size argument). Cada una de estas con una longitud de n_steps y hay solo un valor por cada time step en cada serie. Esto significa que todas las series son univariadas.\n",
        "Cuando se trabaja con series de tiempo(y otro tipos de secuencias como oraciones), las características de entradas son representadas generalmente como un vector de 3 Dimensiones con la forma [batch size, time steps, dimensionality], donde la dimensionality es 1 para series de tiempo univariadas y más de 1 para series de tiempo multivariadas."
      ],
      "metadata": {
        "id": "Lb_yecAZC0eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creemos un set de entrenamiento, validación y test:\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -1] # \n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -1] \n"
      ],
      "metadata": {
        "id": "qhbvoWo4Czls"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train contiene 7000 series de tiempo. Su forma es [7000, 50, 1], mientras que X_valid contiene 2000 y X_test 1000\n"
      ],
      "metadata": {
        "id": "sbYifVa4EwqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"El shape de X_train es: {X_train.shape}\")\n",
        "print(f\"El shape de X_train es: {X_valid.shape}\")\n",
        "print(f\"El shape de X_train es: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61o895N3CrZO",
        "outputId": "94ec8a28-32df-427b-9e5d-acd5fa4e098a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El shape de X_train es: (7000, 50, 1)\n",
            "El shape de X_train es: (2000, 50, 1)\n",
            "El shape de X_train es: (1000, 50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de empezar a utilizar RNNs es a menudo unas métricas de base o sino podemos pensar que nuestro modelo está trabajando bien cuando de hecho lo está haciendo peor que los modelos básicos. Por ejemplo, la forma más simple es predecir el último valor en cada serie. Esto se denomina naive forecasting, y es algunas veces sorprendentemente dificil de superar. "
      ],
      "metadata": {
        "id": "zHm8IlVXJV0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "7WRkTGiYKsnd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = X_valid[:, -1]\n",
        "mse= np.mean(keras.losses.mean_absolute_error(y_valid, y_pred))\n",
        "print(\"Mean squared error {:.4f}\".format(mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNuhKc4OFa4m",
        "outputId": "32b63e4d-39f2-4eae-a5d4-366ddb28995b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error 0.1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Miremos si podemos vencer eso con una RNN simple."
      ],
      "metadata": {
        "id": "Z83qniZqOntU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "keras.layers.SimpleRNN(1, input_shape=[None, 1])])"
      ],
      "metadata": {
        "id": "Y1eSBFnHK1Jh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es realmente la RNN más simple que puedes construir. Esta contiene un solo layer con una sola neurona. No necesitamos especificar la longitud de las secuencias de entrada porque una red neuronal recurrente puede procesar cualquier número de time steps(Por esto es que colocamos la primera dimension de entrada igual a None). La cada SimpleRNN usa de manera predeterminada la función de activación tangente hiperbólica."
      ],
      "metadata": {
        "id": "pW8G82CzO1MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " optimizer = keras.optimizers.Adam(learning_rate=0.001) # Optimizador \n",
        " model.compile(optimizer=optimizer ,loss='mse',metrics=['mse']) # Funcion de costo a optimizar y optimizador"
      ],
      "metadata": {
        "id": "-7lMhsacOkHW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzwfSuOMQwM9",
        "outputId": "22b3c042-e411-4ef1-c7a7-0215d50fcdaf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 4s 11ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0455 - val_mse: 0.0455\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f066cd5ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede ver el MSE alcanza solo 0.010 así que es mejor el modelo base. Otro punto a favor de una RNN, es que en una RNN simple, el número de parametros es el número de neuronas recurrentes en una capa más el término bias."
      ],
      "metadata": {
        "id": "T0AfOpfGRZq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uno1ggr8RN2y",
        "outputId": "f57c0b72-8e17-47e3-b680-d0ac260d2c84"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "91fSMccJTEGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}