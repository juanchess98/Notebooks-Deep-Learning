{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regresión Logistica.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanchess98/Notebooks-Deep-Learning/blob/regresion-logistica/Regresi%C3%B3n_Logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtC5lHSvH0ni"
      },
      "source": [
        "# Regresión Logística\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnPtZ5KmKCaN"
      },
      "source": [
        "La regresión logística es un métdo de clasificación binaria, es decir, la variable dependiente sólo puede tomar dos valores: Verdadero ó Falso, 1 ó 0, etc. \n",
        "\n",
        "Se denimina regresión logística ya que el corazón del método es la llamada función logística o función sigmoide, la cual es de la forma:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDN1UAC_MOPQ"
      },
      "source": [
        "\\begin{equation}\n",
        "  \\sigma(z)=\\frac{1}{1+e^{-z}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2ecYoRbQAFo"
      },
      "source": [
        "Se usa el método de regresión logística para modelar variables dependientes binarias en lugar de la regresión lineal ya que esta última para valores que se encuentran en los extremos de la recta predicha entrega valores menores a cero y mayores a uno, esto va en contra de la definición de probabilidades que están en el rango $[0, 1]$.\n",
        "\n",
        "Es aquí donde difieren los dos métodos ya que la regresión logística utiliza la recta generada por la regresión lineal pero la pasa por la función sigmoide para que el resultado siempre esté entre 0 y 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLEHVRlPH7QI"
      },
      "source": [
        "Teoria\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "044j_wrhIDg2"
      },
      "source": [
        "#Representación grafica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHnGxVKHH5_E"
      },
      "source": [
        "# Optimización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1y1pLv2IC5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhjQ_x6IHQf"
      },
      "source": [
        "# Implementacion en Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFX9gNNKIhtw"
      },
      "source": [
        "def funcion2_RLog(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5):\n",
        "\n",
        "    ## Implementación con Keras\n",
        "    dim = X_train.shape[1]\n",
        "    inputs = Input(shape=(dim,))\n",
        "    preds = Dense(1,activation='sigmoid')(inputs)\n",
        "    model = Model(inputs=inputs,outputs=preds)\n",
        "    sgd=keras.optimizers.SGD(lr = learning_rate)\n",
        "    model.compile(optimizer=sgd ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
        "    model.fit(X_train,Y_train, batch_size=1, epochs=num_iterations, shuffle=False)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dmGIvwaIaeH"
      },
      "source": [
        "Explicacion adicional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U4D6pIsIMux"
      },
      "source": [
        "# Implementacion en Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyjf__MLWs9k"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt-hHHiPWu6Q"
      },
      "source": [
        "X_, y_ = datasets.make_classification(n_samples=100, n_features = 6, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2, random_state=1)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "\n",
        "n_samples, n_features = X_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecWUfk2te6fz"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rv3HmWce53J"
      },
      "source": [
        "model = LogisticRegression(n_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtLt9TQh5cI"
      },
      "source": [
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(params= model.parameters(),lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GtwUH--iO_6"
      },
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  #backward\n",
        "  loss.backward()\n",
        "\n",
        "  ##update\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad() ## clean gradients to next iteration\n",
        "\n",
        "  if(epoch+1) % 10 == 10:\n",
        "    print(f'epoch: {epoch + 1}, loss = {loss.item():.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdTOUBwVlHb3",
        "outputId": "f17e72af-2f13-4ddd-caf4-9e4c0f404f0f"
      },
      "source": [
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy =  {acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy =  0.3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2d3X8w1XWIL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGP_okH0IZ9C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM4FV6YmIKk_"
      },
      "source": [
        "#grafico"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bBS0joSIQT-"
      },
      "source": [
        "Explicación adicional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvhV5E9FIS0O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}