{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HZ_eV2jVRtO"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juanchess98/Notebooks-Deep-Learning/blob/transfer_learning/transfer_learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvAnKrsVVRtR"
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RAOxRPUVRtS"
   },
   "source": [
    "Aprender una tarea nueva puede ser un proceso que lleve una considerable cantidad de tiempo. Sin embargo, los seres humanos tienen la capacidad de asociar nuevas tareas con otras que ya sabe como ejecutar y aplicar este conocimiento para reducir el tiempo y costo de aprendizaje. Por ejemplo, si una persona sabe como manejar una bicicleta, para esa persona será mucho más fácil aprender a manejar una motocicleta. Asimismo, una persona que domine el idioma español tendrá mucha más facilidad para aprender otro idioma similar, como el portugués, que una persona de origen alemán o japonés.\n",
    "\n",
    "Este mismo concepto se puede aplicar a las máquinas inteligentes y se le conoce como *Transfer Learning* o Aprendizaje por transferencia. En este caso, un modelo desarrollado para una resolver una tarea puede usarse como punto de partida para resolver otra tarea similar.\n",
    "\n",
    "Pueden presentarse diferentes escenarios en la aplicación de *transferencia de aprendizaje* a un dataset nuevo, pero generalmente se puede reducir a cuatro casos:\n",
    "\n",
    "1. La nueva base de datos es numerosa y se parece muy poco a la base de datos del modelo pre-entrenado\n",
    "2. La nueva base de datos es numerosa y parecida a la base de datos del modelo pre-entrenado\n",
    "3. La nueva base de datos es pequeña y diferente de la base de datos del modelo pre-entrenado\n",
    "4. La nueva base de datos es pequeña y parecida a la base de datos del modelo pre-entrenado\n",
    "\n",
    "En la siguiente gráfica tipo plano cartesiano pueden visualizarce mejor los posibles escenarios, dividiendo el plano en cuadrantes que representan cada escenario y dónde en la dirección de crecimiento del eje $x$ se indica la similaridad de los dos datasets y el eje $y$ el tamaño del nuevo dataset.\n",
    "\n",
    "**(Insertar imagen de cuadrantes aquí)**\n",
    "\n",
    "Para cada escenario existe una metodología diferente a implementar y en el curso de este notebook trataremos de ejemplificar cada una con la ayuda de los frameworks de Keras y Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LC3LxHxRVRtT"
   },
   "source": [
    "## Transfer Learning en Keras\n",
    "\n",
    "La metodología de *Transfer Learning* en Keras suele tener el siguiente flujo de trabajo:\n",
    "\n",
    "1. Tomar las capas de un modelo previamente entrenado\n",
    "2. Congelarlas para no perder la información que contienen en futuros entrenamientos\n",
    "3. Añadir nuevas capas para entrenar sobre las capas congeladas\n",
    "4. Entrenar las capas nuevas con los datos de interés.\n",
    "\n",
    "Un último paso, opcional, es realizar *fine tuning* o sintonización fina. Esto consiste en descongelar todo, o una parte del modelo obtenido en los pasos anteriores y entrenarlo con los nuevos datos a una tasa de aprendizaje muy baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nn2eoOcgVRtU"
   },
   "source": [
    "#### Congelamiento de capas con el atributo *trainable*\n",
    "\n",
    "En Keras las capas y los modelos tienen tres atributos:\n",
    "\n",
    "1. **weights:** lista de todos los pesos de la capa\n",
    "2. **trainable_weights:** lista de todos los pesos que serán actualizados por el optimizador (gradiente descendente, etc) para minimizar la función de costo durante el entrenamiento\n",
    "3. **non_trainable_weights:** lista de todos los pesos no entrenables\n",
    "\n",
    "Para establecer si un peso es entrenable o no, las capas y los modelos tienen otro atributo: **trainable**. El atributo **trainable** es de tipo booleano y llevarle un valor de **False** hace que todos los pesos en esa capa sean no-entrenables, es decir, se *congelan* los pesos de dicha capa. Por ejemplo:\n",
    "\n",
    "    layer = keras.layers.Dense(3)  # Se crea la capa\n",
    "    layer.build((None, 4))         # Se crean los pesos\n",
    "    layer.trainable = False        # Se congela la capa\n",
    "    \n",
    "Con esto se asegura que los pesos de esta capa no sean actualizados durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i4aA617RVRtV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaMWtb0rXZKX"
   },
   "source": [
    "Se carga el modelo de la arquitectura VGG16 entrenado con la base de datos ImageNet la cual contiene 1000 clases. El tamaño de las imágenes de entrada de este modelo es de 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TR0rOqciVRtY",
    "outputId": "7bc6872f-82b6-450a-d3af-cce22f35672d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f9233f92d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.applications.VGG16(\n",
    "    include_top=False,  # Incluir las tres capas convolucionales del tope de la red.\n",
    "    weights=\"imagenet\",  # Cargar pesos pre-entrenados en ImageNet.\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
