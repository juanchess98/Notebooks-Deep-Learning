{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regresion_Lineal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanchess98/Notebooks-Deep-Learning/blob/regresion-lineal/Regresion_Lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AczP6mv_D086"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0sgCYz2F03Z"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsX-wD3lKcC7"
      },
      "source": [
        "# Teoria \n",
        "\n",
        "Es un método para predecir una variable objetivo ajustando la mejor relación lineal entre la variable independiente (predictor) y la dependendiente (target) $$ \\hat{y} = mx + b$$\n",
        "\n",
        "- $\\hat{y}$ es el valor predicho.\n",
        "- $x$ es el valor de la característica.\n",
        "- $m$ y $b$ son la pendiente y el termino de sesgo respectivamente. Estos son los parametros del modelo que se deben ajustar para obtener la mejor aproximación. Usualmente se denotan con un vector de la siguiente manera:\n",
        "$$\\theta = \\left [ \\theta _{0}, \\theta _{1}, ..., \\theta _{p} \\right]$$ donde $p$ denota el número de características o variables independientes del modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqWO_FINKjYS"
      },
      "source": [
        "# Ilustración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHHc9j6uZ46x"
      },
      "source": [
        "# ¿Cómo encontrar la mejor representación?\n",
        "\n",
        "Entrenar a un modelo significa establecer los parametetros del modelo tal que este se ajuste de la mejor manera posible al conjunto de entrenamiento. Para este proposito se necesita establecer una medida que indique que tan bien o mal el modelo se está ajustando a estos. Esto se denomina Función de costo.\n",
        "\n",
        "$$L(\\mathbf{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\left (\\hat{y}^{i} - y^{i}  \\right )^{2}$$\n",
        "\n",
        "se debe determinar  los valores de $w$ y $b$ que optimizan esta función.\n",
        "\n",
        "Para abordar este problema de optimización se pueden utilizar los siguientes metodos:\n",
        "- Solución análitíca\n",
        "- Descenso del gradiente y variantes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cYukU5ZKin_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALP6PfT4Khty"
      },
      "source": [
        "print('hi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSFo_a5k8sjY"
      },
      "source": [
        "# Gradiente Descendente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1kL3Zed8xFp"
      },
      "source": [
        "# Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWGR32cH8xJS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adhgS6ZeKsDG"
      },
      "source": [
        "# Implementación Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_SnOZLE70QF"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import keras\n",
        "\n",
        "def funcion3_RLineal(X, Y, dim = 1, num_ite = 50):\n",
        "  inputs = Input(shape=(dim,))\n",
        "  preds = Dense(1,activation='linear')(inputs)\n",
        "  model = Model(inputs=inputs,outputs=preds)\n",
        "  sgd=keras.optimizers.SGD(lr = 0.001)\n",
        "  model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
        "  model.fit(X,Y, batch_size=1, epochs=num_ite, shuffle=False)\n",
        "  return  model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BFWypuXLa8Q"
      },
      "source": [
        "Explicación relacionada a la implementación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIg82wurLhx5"
      },
      "source": [
        "# Observación ajuste de parametros -- Helper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMdxO9n-KyvT"
      },
      "source": [
        "# Implementación Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5sLs-XkKPIE"
      },
      "source": [
        "1) Design Model\n",
        "2)Construct Loss and optimizer\n",
        "3)Training Loop: Forward pass, backward pass, update weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNzXJRM5K6_3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW5cHFLTK21k"
      },
      "source": [
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features = 1, noise = 20, random_state=1)\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0],1) ##reshape tensor\n",
        "\n",
        "n_samples, n_features = X.shape"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdyRdM0nK3M8"
      },
      "source": [
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(in_features = input_size, out_features = output_size )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33StE7p_K3ay"
      },
      "source": [
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(params= model.parameters(),lr = learning_rate)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVlRRbVNDz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8198c2d-9b8a-42c6-c2cf-1031a0da3679"
      },
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "\n",
        "  #backward\n",
        "  loss.backward()\n",
        "\n",
        "  ##update\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad() ## clean gradients to next iteration\n",
        "\n",
        "  if(epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch + 1}, loss = {loss.item():.4f}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10, loss = 339.8741\n",
            "epoch: 20, loss = 337.9137\n",
            "epoch: 30, loss = 336.4799\n",
            "epoch: 40, loss = 335.4309\n",
            "epoch: 50, loss = 334.6634\n",
            "epoch: 60, loss = 334.1019\n",
            "epoch: 70, loss = 333.6909\n",
            "epoch: 80, loss = 333.3901\n",
            "epoch: 90, loss = 333.1698\n",
            "epoch: 100, loss = 333.0086\n",
            "epoch: 110, loss = 332.8906\n",
            "epoch: 120, loss = 332.8041\n",
            "epoch: 130, loss = 332.7408\n",
            "epoch: 140, loss = 332.6945\n",
            "epoch: 150, loss = 332.6605\n",
            "epoch: 160, loss = 332.6356\n",
            "epoch: 170, loss = 332.6175\n",
            "epoch: 180, loss = 332.6041\n",
            "epoch: 190, loss = 332.5943\n",
            "epoch: 200, loss = 332.5872\n",
            "epoch: 210, loss = 332.5819\n",
            "epoch: 220, loss = 332.5781\n",
            "epoch: 230, loss = 332.5753\n",
            "epoch: 240, loss = 332.5732\n",
            "epoch: 250, loss = 332.5717\n",
            "epoch: 260, loss = 332.5706\n",
            "epoch: 270, loss = 332.5698\n",
            "epoch: 280, loss = 332.5692\n",
            "epoch: 290, loss = 332.5688\n",
            "epoch: 300, loss = 332.5685\n",
            "epoch: 310, loss = 332.5682\n",
            "epoch: 320, loss = 332.5680\n",
            "epoch: 330, loss = 332.5679\n",
            "epoch: 340, loss = 332.5678\n",
            "epoch: 350, loss = 332.5677\n",
            "epoch: 360, loss = 332.5677\n",
            "epoch: 370, loss = 332.5677\n",
            "epoch: 380, loss = 332.5677\n",
            "epoch: 390, loss = 332.5676\n",
            "epoch: 400, loss = 332.5676\n",
            "epoch: 410, loss = 332.5676\n",
            "epoch: 420, loss = 332.5676\n",
            "epoch: 430, loss = 332.5676\n",
            "epoch: 440, loss = 332.5676\n",
            "epoch: 450, loss = 332.5676\n",
            "epoch: 460, loss = 332.5676\n",
            "epoch: 470, loss = 332.5675\n",
            "epoch: 480, loss = 332.5675\n",
            "epoch: 490, loss = 332.5676\n",
            "epoch: 500, loss = 332.5675\n",
            "epoch: 510, loss = 332.5675\n",
            "epoch: 520, loss = 332.5676\n",
            "epoch: 530, loss = 332.5676\n",
            "epoch: 540, loss = 332.5675\n",
            "epoch: 550, loss = 332.5675\n",
            "epoch: 560, loss = 332.5675\n",
            "epoch: 570, loss = 332.5676\n",
            "epoch: 580, loss = 332.5675\n",
            "epoch: 590, loss = 332.5676\n",
            "epoch: 600, loss = 332.5676\n",
            "epoch: 610, loss = 332.5676\n",
            "epoch: 620, loss = 332.5676\n",
            "epoch: 630, loss = 332.5676\n",
            "epoch: 640, loss = 332.5676\n",
            "epoch: 650, loss = 332.5676\n",
            "epoch: 660, loss = 332.5676\n",
            "epoch: 670, loss = 332.5676\n",
            "epoch: 680, loss = 332.5676\n",
            "epoch: 690, loss = 332.5676\n",
            "epoch: 700, loss = 332.5676\n",
            "epoch: 710, loss = 332.5676\n",
            "epoch: 720, loss = 332.5676\n",
            "epoch: 730, loss = 332.5676\n",
            "epoch: 740, loss = 332.5676\n",
            "epoch: 750, loss = 332.5676\n",
            "epoch: 760, loss = 332.5676\n",
            "epoch: 770, loss = 332.5676\n",
            "epoch: 780, loss = 332.5676\n",
            "epoch: 790, loss = 332.5676\n",
            "epoch: 800, loss = 332.5676\n",
            "epoch: 810, loss = 332.5676\n",
            "epoch: 820, loss = 332.5676\n",
            "epoch: 830, loss = 332.5676\n",
            "epoch: 840, loss = 332.5676\n",
            "epoch: 850, loss = 332.5676\n",
            "epoch: 860, loss = 332.5676\n",
            "epoch: 870, loss = 332.5676\n",
            "epoch: 880, loss = 332.5676\n",
            "epoch: 890, loss = 332.5676\n",
            "epoch: 900, loss = 332.5676\n",
            "epoch: 910, loss = 332.5676\n",
            "epoch: 920, loss = 332.5676\n",
            "epoch: 930, loss = 332.5676\n",
            "epoch: 940, loss = 332.5676\n",
            "epoch: 950, loss = 332.5676\n",
            "epoch: 960, loss = 332.5676\n",
            "epoch: 970, loss = 332.5676\n",
            "epoch: 980, loss = 332.5676\n",
            "epoch: 990, loss = 332.5676\n",
            "epoch: 1000, loss = 332.5676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "p662aAfXOXxA",
        "outputId": "79797c83-7c5e-4e46-ea5b-540eeacc5d73"
      },
      "source": [
        "#plot\n",
        "predicted = model(X).detach().numpy() # detach --gradient argument set to false\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD7CAYAAACCEpQdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5BdZZ3n8fc3MWFI0AE6IcYk3R2p1p2gyJguCge1EKPG7NaAOlo4HUSjxhBwsGqmXNje2tU/suvW1mDByq/wS6RbWGocltSCMCEiOBaojUYIZJAW0iExkITIz3b5kf7uH+fc9Ln3nnN/9D3nnvvj86rq6nufe+69D13ke5/7PN/n+5i7IyIi3WVW3h0QEZHmU/AXEelCCv4iIl1IwV9EpAsp+IuIdCEFfxGRLtRw8DezZWZ2n5k9bmaPmdlFYfvxZrbVzJ4Mfx8XtpuZXW5m42b2iJm9v9E+iIhIfdIY+b8J/L27rwBOAy4wsxXAxcA2dx8AtoX3AT4JDIQ/64GrUuiDiIjU4S2NvoC77wP2hbdfNrOdwBLgLOCM8LKbgJ8C/zFs/4EHu8seMrNjzWxx+DqJFixY4P39/Y12V0Skazz88MMH3X1h3GMNB/8oM+sH/hL4BbAoEtCfBRaFt5cAz0Setidsqxj8+/v7GRsbS7O7IiIdzcwmkh5LbcHXzI4BfgR8w91fij4WjvLrriNhZuvNbMzMxg4cOJBST0VEJJXgb2ZzCAL/qLv/c9j8nJktDh9fDOwP2/cCyyJPXxq2lXH3ze4+6O6DCxfGfnMREZEZSCPbx4DrgZ3ufmnkoS3AeeHt84A7Iu1fCLN+TgNerDbfLyIi6Upjzv904FzgUTPbHrb9J+A7wG1m9mVgAvhc+NhdwBpgHJgEvpRCH0REpA5pZPv8K2AJD3805noHLmj0fUVEZOa0w1dEpAsp+IuIdCEFfxGRUqOj0N8Ps2YFv0dHc+nGddfBvfdm89qpbvISEWl7o6Owfj1MTgb3JyaC+wBDQ03pwvg4DAxM3/e+fti0KdX318hfRCRqeHg68BdMTgbtGXOHNWuKA/9+Fk5/AKX4DUTBX0Qkavfu+tpTcvfdwSzTj38c3P8B5+IYCzkYNKT8AaRpHxGRqN7eYKQd156B556Dt799+v573wsPPzqXObxRfnGKH0Aa+YuIRG3aBPPmFbfNmxe0p+zYY4sD/9gYPPIIzOl7R/wTUvwAUvAXEYkaGoLNm6GvD8yC35s3p7rYunVr8NIvvjjd5g4rV4Z3mvABpGkfEZFSQ0OZZPZMTcHs2cVtO3bASSfFvD8Ec/y7dwcjfmX7iIi0n3/4h+LAv2pVMNo/aXvCnoKhIdi1K/jE2LUr9Q8jjfxFRDK0fz8sWlTcNjkJRx9NrnsKNPIXEclIT09x4L/qqmC0f/TRYUOOewo08hcRSdm998LHPlbc5nFnGea0pwA08hcRSY17kMUTDfyPPpoQ+CE5dTOjPQVRCv4iIin45jeDNduCM84Igv573lPhSU3cU1BK0z4iIg04cABOOKG47dVXy2N6rCakdCZJ6wD3G8xsv5ntiLR9y8z2mtn28GdN5LFLzGzczJ4ws0+k0QcRkRlpoHzzCScUB/4rrghG+zUF/oKMUzqTpDXt831gdUz7d939lPDnLgAzWwGcA5wUPudKM5sd81wRkWwVUi0nJoKoHVc9M+bD4b77grn9AwemL3OHjRub/R8wc6kEf3d/ADhU4+VnAbe6+2vu/jTBQe6nptEPEZG6VEu1LPlw8IkJbO0QZ545fflvf1thQbeFZb3ge6GZPRJOCx0Xti0BnolcsydsExFprmqplpEPh0v4b8xiOsp/6ENB0D/55Kw7mY0sg/9VwInAKcA+4B/rfQEzW29mY2Y2diD6/UpEpB5J8/rVUi1372Y3yzCc73DJkYdf4RgeeCDTHmcus+Dv7s+5+2F3nwKuZXpqZy+wLHLp0rAt7jU2u/uguw8uXLgwq66KSCerNK9fJdXSfIo+pr8dXM7XcYz5fQua+V+QicxSPc1ssbvvC+9+CihkAm0BfmhmlwLvAAaAX2bVDxHpcpXm9Xftmr4mkmr57fEhvmXFT3HChibl4WctleBvZrcAZwALzGwP8F+BM8zsFMCBXcDXANz9MTO7DXgceBO4wN0Pp9EPEZEy1eb1I+Wb40ou3/3Nn/CJ/70OdltT8/CzZt4my9SDg4M+NjaWdzdEpN3098cfy9jXNz3yJ0jdLNUm4TGRmT3s7oNxj6m8g4h0tirz+g8+WB74n3uu/QN/NQr+ItLZKhzLaAZ/9VfFl7vN4oRT++va6duOFPxFpPOVlFD4+E1DZaN9nzc/WNRN2unbYRT8RaRrTE0Fg/+tW6fb/u7vwPv6cztUJS+q6ikiXaHigu7/yu9Qlbxo5C8iHe3++8sD//h4yYJujoeq5EXBX0RmroFyyM1gFhyqEuUOJ55YcmGOh6rkRcFfRGamlnLIOTn55PLRvnuF9M0KGUGdSpu8RGRmatw81UxxO3TPPhtuvz2X7uROm7xEJB3RaZ64wA/pLpLWMa1kVh743bs38Fej4C8itSmd5kmS1iJpjdNKP/95+RTPo492/g7dRmnaR0RqkzTNEzVvXnpz5TVMK3ViPZ40adpHRBpXaToni0XSCtU4V66sc0FXyij4i0htkqZz+vqOlE1INTsm5v2c4ICVX/96um3NGgX9mVDwF5HaNDsXvuT9DC86QxeCoH/nndm8fadT8BeR2jQ7Fz58v4fefjZWEvS3b68y2m/xzWetQAu+ItKyZrSgW8gSihZqS3Mhuo1kvuBrZjeY2X4z2xFpO97MtprZk+Hv48J2M7PLzWzczB4xs/en0QcRSVmOo+fe3vLAPzVV49x+pTN75Yi0pn2+D6wuabsY2ObuA8C28D7AJwkObR8A1gNXpdQHEUlLs0o3jI7CggVBpDfDexZgBs88M33JX/xF0IW4bwGxqp3ZK0BKwd/dHwAOlTSfBdwU3r4JODvS/gMPPAQca2aL0+iHiKSkGaPn0VH40pfg+eeBcEH30MGiS9zh8cfrfN0urNA5E1ku+C5y933h7WeBReHtJUDkc509YZuItIpmjJ6Hh+GNN/i//PuyBd37OCM4YGUm3zS6sELnTDTlMBd3dzOre2XZzNYTTA3Rq09tkebp7Y3fXZvmv8Pdu8uCPhAcpQgwQTDVBPUt1BauHR4OPqx6e4PA32WLvdVkOfJ/rjCdE/7eH7bvBZZFrlsatpVx983uPujugwsXLsywqyJSJOPRs1mwWStqCpsO/AUznWoqObNXgb9clsF/C3BeePs84I5I+xfCrJ/TgBcj00Mi0goyyulPWrh1rDTsT9NCbSbSSvW8BXgQeLeZ7TGzLwPfAT5mZk8Cq8L7AHcBTwHjwLXAxjT6ICIpS3n0bBZkjUb5yCjes6DyEzXlm4m0sn0+7+6L3X2Ouy919+vd/Xl3/6i7D7j7Knc/FF7r7n6Bu5/o7u91d+3cEulgt91WPtofGQlz9oeG4ODB4M7IiBZqm6gpC74i0p3q2qGrhdqmUvAXkdTFBf2pqRo2ag0NKdg3iQq7iXSLJpRrSFzQTdqhqwJsudHIX6QblBY7K5RrgNRG2nUXYWtCnySZRv4i3SDtcg2REfvtJ3ytLPDfeGMNRdhUgC1XGvmLdIM0yzVERuyGw4Hih2uuEp90HnC1c4IlFRr5i3SDNIudDQ9jk6+WlWY4zGx8pI45+9mz62uXVCn4i3SDlMo1uINN7Cpvx5jFVH1TNocP19cuqVLwF+kGKZRriN2hW1qPZ2Ki9qydvr762iVVCv4i3aJSuYYKKZfXXlueyfNt/kt5EbaCWg9+UenlXGnBV6TbVUi5tLXl3wwSg35UIWun0jcL7ejNlQ5wF+l2/f1lGTZxdfbfZDazmSprT2QWfMuQ3GR+gLuItLGSdM/YA1b6+usL/KBqnC1OwV+k24VB2sLl2yj3MG8/bn6+Es3dtzwFf5Eud+2qW8uC/no2B3P7hcXfaLZQktmzUz34RbKlBV+RLhZk8ZxW1OY2a3qbbmm9naGh8gViCEb6CvhtJfORv5ntMrNHzWy7mY2Fbceb2VYzezL8fVzW/RCR0OhocIZuSdLO668Hc/tl9RlK6+1kdMSjNFezpn0+4u6nRFadLwa2ufsAsC28L9I5mlGqeCbvMToan745MsqcOdReA0gHpLe9vOb8zwJuCm/fBJydUz9E0leYFpmYCEbRtW56yvg9zMrz9o/s0C2M7NOsASQtrRnB34F/MbOHzSycPGSRu+8Lbz8LLGpCP0Saoxmliut4j+uuK5/i+SI3Fm/WKozsteu2azRjwfeD7r7XzE4AtprZv0UfdHc3s9idZuGHxXqAXo08pF0kTZ0U6t6ksZu1xumZ2ANW4nboFv59addt18h85O/ue8Pf+4HbgVOB58xsMUD4e3/Ccze7+6C7Dy5cuDDrroqkI2mgYpbeVFCV6Zm4Bd3XmBsf+EtH9prP7wqZBn8zm29mby3cBj4O7AC2AOeFl50H3JFlP0SaKm7qxCw+i2bt2pktCFeYnkka7c/ljfIHlKnTtbIe+S8C/tXMfgv8ErjT3e8GvgN8zMyeBFaF90U6Q1wqZKUaWnHfAqpl8hTeo6fnSJNNvlq+oOth3n4cM43su1imwd/dn3L394U/J7n7prD9eXf/qLsPuPsqdz+UZT9Emq506qRajfroYm1cJs+558LGjeXP+9OfuJqvle3QPe20yOdNlhk8zUhplUyovINIM9RSG6ewWBuXyeMOV19dHFzD4xTP5+riS3sW8OC+/umAvGZNNhk8zUhplcyopLNIs4yOBoE96YDyvr7gW8KsWcnTRH19wbx+zEatSY7maP5f+XPM4MwzYXw83QyemFLQR/q4a1djry2pqFTSWbV9RLJUCPjRoAvxtXEKj/X2Jn9ATEzUf8CKO/zkJ3DzzenO79e6G1hakqZ9RLKSNC0ClWvjbNoUm6AfW3K59AzdJO7pbjID7QZucwr+IlmptAu3sCB8881B+7nnFpdP3rDhyAfADXypLOi/j+3lQb+vryj7p0zaI3LtBm5rmvYRyUq1aZEKZ+dy5ZVw+um1T/EU5tlHR4MPkrg1g7RH5NoN3NY08hfJSrVpkQrfDOKKsL3C/Np26MZlFWU1Itdu4Lal4C+ShdFReOWV8vZoEE74ZmATu8raHGM+JR8UpesFhW8Sr75afF1Pj3bxShlN+4ikLe6kKwiC8GWXTQfh44+H558/8nDswelJi7lx6ZRx3yQAjjlGgV/KaOQvkrZagvDoKLz4IgBXsLEs8B93XIWyDBA/haPUS6mDRv4iaaslCA8Pw5tvxo/2exbAwYPQn5Dv39MTP5JP2h+g1EuJoZG/SNqSgu3xxx+pg2MTu8oC/x85NpjmKUwFJaVSXnZZ/Osr9VLqoOAvkra4IDx3Lrz0UrBD16fKnuIYx/JicWO9B6XrYHWpg2r7iGShtKzDK69gzx8suyx2QbenJ5j2EWlQpdo+GvmLZCGS/37df95Ve+CfOzd5WkckRVrwFclQ1TN0e3qCLCDtkJUm08hfpFQKB5TEnaF78OhlxYG/sHhb2CG7aVMwVaSDUaQJcgv+ZrbazJ4ws3EzuzivfogUSeGAktjRvkPPtd9JXozVwSjSZLkEfzObDVwBfBJYAXzezFbk0ReRIpUqcVYRN9p3m4X39U9X60yqg9PA+ybSEYtSQV4j/1OB8fCM39eBW4GzcuqLyLQZ7JK96aYKc/vRUfzGjcnBOO3dufomIVXkFfyXAM9E7u8J20SaLzpCnpXwTyJh45YZfPGLxW3e11+eyTM5GZzBmxSM0z4YJYtvEtJRWnrB18zWm9mYmY0dOHAg7+5IJyodIR8+XH5NzC7ZuCmeZ58Ny+gnjdZL99REg3Hau3NV50eqyCv47wWWRe4vDduKuPtmdx9098GFCxc2rXPSQarNeycVYZs9O3GXbNKC7qJF4Z16RuuFYJz27lwdsShV5BX8fwUMmNlyM5sLnANsyakv0qlqmfdOGglPTZUtzMYu6HrMoVlxo/i4TwzILhirzo9U4+65/ABrgN8BvweGq12/cuVKF6lLX18hNhf/9PVVv6an58glt9wSf4nPm+c+MhL/3iMjwWubBb/PPz+4PvoC0eePjFR+fCZK+9DIa0lbAsY8KQYnPdBqPwr+Ujez+KhtNn3NyIj73Lnl18yZ4z4yEh/04z5MagmslYJxLR9UInWqFPxV2E06V39/fH370lOwFiwoOlEL4k/V2sMSlvCH+PeaN6+xOfpZs+IPXTcLpp9EZkCF3aQ71TrvfehQ0d3YA1b6+pMDPzSeRqkFWmkyBX9pfTPdqVrIoOnpmW47+ujy68IAa3hZ4C/Mv8R+kJRqJI1SC7TSZAr+0trS2Kn6pz9N337++bLnbz3n+vjR/kjkPaKpmEkaGaXrIBZpMgV/aW217FSt9M2g0vNHRzGDj/+PjxY97H3904E/+roQrBWMjGQzSq9U+0ckbUkrwa32o2yfLhLNionLgIlm7FRLkUx4jbiX3PNnJ9aeeqk0SmkDKNtHWlLpUYeFkfP69fG7bqMKGTvVMnpiHo+d4inU4ik8LyYDqOhxkTagbB9pPUlz+RddVD3wR6dYqtWw2bQJ5swBEhZ0w9YjJiaSA3+l91P5ZGkzCv6Sj6S5+KSgC/ELoTWkSP7MP1h5tF/6HpX6EPd+Kp8sbUjTPpKPpE1NSZKmWwqBN/pBEtlwVfUM3XqNjJQvxNa6mUykyTTtI60nacTe01N7Jk1hzWByMqjCCUe+Gdja8sA/QW9jgb+nJz4DR+WTpQ0p+Es+kjY1XXZZbfnu0akWCOrwhx8StrY8QDtGb9H5QTEKHyBxCn2Lo9250oYU/CUfSZuaoDwDKG60HbNmYJOvlgV+HxnF580vfu7cuUcWgY+YNy/4MInbxdvTU3nDlXbnSjtKygFttR/l+XeBuNx6s6AccqlI/v5DnBpffTP6uqXllXt6pi/s6Wk8f195/9KCUJ6/tIWkhVMzuPnm4pF3eG1sFk+l/6WrLBAfuaaWbx8iLU4LvtIeKp19u3ZtUf68TewqC/y//7OTiuvxxKlWLkJpm9IlNPKX1pE08o+aOxd7/bWyZu/rr22EXq1uvtI2pYPkMvI3s2+Z2V4z2x7+rIk8domZjZvZE2b2iaz6IG1m06bks24Jd+iWBP7CxH3NhdCqZeYobVO6RNbTPt9191PCn7sAzGwFwYHtJwGrgSvNrEKOnXSNoSHYsKHsA+A3nFL/3H6Sapk5StuULpHHnP9ZwK3u/pq7Pw2MA6fm0A9pBaU1cU4/PVjcDevmG877+U3RUxybWeCH6nXzlbYpXSLr4H+hmT1iZjeY2XFh2xIo2m2zJ2yTVpZF4bKkxVXiF3R/x0CwQzd6MtdMVKqbr0NVpEs0FPzN7F4z2xHzcxZwFXAicAqwD/jHGbz+ejMbM7OxAwcONNJVaURWGTAJmTdJO3QHGA/ufO5zM3u/0dGgYqdZ8LNgQfx/gw5VkW6QtAEgzR+gH9gR3r4EuCTy2D3AB6q9hjZ55aivr3wHFQTtlVTb+FRy0ErsRq3zzy8/kCV6qEqtRkbc58wpf4O5c7UhSzoWFTZ5ZZntszhy91PAjvD2FuAcMzvKzJYDA8Avs+qHpGAmGTCjo7BuXfG3hXXrikfa4SLq0/SXTfEs4tkgffO228pXdkuPcazF8DC88UZ5++uv1/9aIh0gszx/M7uZYMrHgV3A19x9X/jYMLAOeBP4hrv/uNrrKc8/RzPJfU86EKWnBw4eDG6PjiZO8VRVyMuvVaUS0vW+lkibyCXP393Pdff3uvvJ7v7XhcAfPrbJ3U9093fXEvglZzPJgEk6ECVs/8hHKAv8u+irveRyvamXla5XGqd0IZV3kOpSzoAxg5/+tLjNMfqocSPVTFIvI8c5Fpk7V2mc0pUU/KU29WbAxKRj1nSGbqXXa+SDZ2gIbryxuF89PXDDDcrmka6k4C/ZuOyyIyPtZ1lUFvQ//O+ew62O//2OOabx1MuhoWC9oZDrc/CgAr90LQV/SU90I9jwMHzlKxjOYp4tuswx7t/9Tjj++NpfW7V1RFKl4C/pKNkItmHiYuyqK4sueYal01M8hc1dpQvJSYXdtCgrkioFfyk3k1IOkd26hnMNG4oedoyl7C1+zqFD5QvJGzaoto5IEyj4S7G4Ug5r1yaXQijYvTt+QddmBZu14vT2li8kX3mlauuINIGCvxSLq7cDQX5+Qj2fF14A8+JNUudwSzDFUzgGsZ7RvGrriGROwV+KVVpYjSmrYAbHHVd8mWPcwt9OB3hVyhRpOQr+Uqzawmr44TA8XL42++wVPwqmeOICvEbzIi3lLXl3QFrMpk3B9E7c1A9Ab29sQk5QNuczsPEzWfZORFKi4C/FCiPyiy4qq89jOJTUd8uoLqCIZEzTPlKusBP2/PPBjJc5piyLZ906BX6RdqaRvyS7666yLB4gmNe/flfTuyMi6dHIX2LdfXdwjm7UsywK0jdVakGk7WnkL2ViF3SjlTdVakGk7WnkL0d8+MPlgT+25PKaNc3rlIhkoqHgb2afNbPHzGzKzAZLHrvEzMbN7Akz+0SkfXXYNm5mFzfy/hJjBnV5XnstCPo/+1nxyySWZbjrrjR6KiI5anTaZwfwaeCaaKOZrQDOAU4C3gHca2bvCh++AvgYsAf4lZltcffHG+yHwHRdnkKO/sREcB8SN1Ul5+wDa2dwcLuItIWGRv7uvtPdn4h56CzgVnd/zd2fBsaBU8OfcXd/yt1fB24Nr5U0xNXliSnJALBtW3ngf+GFkvTNpLl9zfmLtL2s5vyXAM9E7u8J25LaY5nZejMbM7OxAwcOZNLRjpI0Ii9pN4NVq6bvn3BCEPT//M9LnjeTg9tFpC1UDf5mdq+Z7Yj5yXzE7u6b3X3Q3QcXLlyY9du1vyoj9TPPjFnQdXjuuYTXU0E2kY5Vdc7f3VdVuybGXmBZ5P7SsI0K7dKouLo88+bx+rf/O0eVBP2bboIvfKGG1xwaUrAX6UBZ5flvAX5oZpcSLPgOAL8EDBgws+UEQf8c4G8z6kP3KQTp4eFgqqe3N9io9cXiy1SWQUQaTfX8lJntAT4A3Glm9wC4+2PAbcDjwN3ABe5+2N3fBC4E7gF2AreF10pawtLJ922bKtuhe+iQAr+IBMzbJBoMDg762NhY3t1oC6Xz+sceC3/8Yz59EZH8mNnD7j4Y95h2+HaQCy+MX9BV4BeRUgr+HeDwzT/EDK64Yrrtjjs0xSMiyVTYrc2duOhlntpfvGbu8+bDy5sBZemISDyN/NvUk08GUzxP7X/rkbZXmB8UYUvY1SsiUqDg34bM4F3vmr7/dS7HMeYTye9X/R0RqUDBv41873sxC7p9/VzOReUXq/6OiFSg4N8GDh8Ogv7Xvz7d9rOfhQu6qr8jIjOg4N/i3v1ueEvJsrw7fPCD4R3V3xGRGVC2T4saH4eBgeK2l1+GY46JuVj1d0SkThr5tyCz4sC/cWMw2o8N/CIiM6CRfwu56qog0Edpo5aIZEHBvwUcPlw+r3///cGB6iIiWVDwz9mKFbBzZ3GbRvsikjXN+efk6aeDuf1o4H/pJQV+EWkOBf8cmME73zl9f/36IOi/9a3JzxERSZOCfxNdc018yeVrrsmnPyLSvRo9yeuzZvaYmU2Z2WCkvd/M/mRm28OfqyOPrTSzR81s3MwuNysNh51naioI+hs2TLfdd5+meEQkP40u+O4APg3EjV1/7+6nxLRfBXwV+AVwF7Aa+HGD/WhZ73sfPPJIcZuCvojkraGRv7vvdPcnar3ezBYDb3P3hzw4P/IHwNmN9KFVFRZ0o4H/xRcV+EWkNWQ557/czH5jZveb2YfCtiXAnsg1e8K2jlK6oPvlLwdB/21vy69PIiJRVad9zOxe4O0xDw27+x0JT9sH9Lr782a2Evg/ZnZSvZ0zs/XAeoDeNihRfN118NWvFrdppC8irahq8Hf3VfW+qLu/BrwW3n7YzH4PvAvYCyyNXLo0bEt6nc3AZoDBwcGWDaNTUzB7dnHbtm1w5pn59EdEpJpMpn3MbKGZzQ5vvxMYAJ5y933AS2Z2Wpjl8wUg6dtDW1i5sjzwuyvwi0hrazTV81Nmtgf4AHCnmd0TPvRh4BEz2w78E7DB3Q+Fj20ErgPGgd/Tppk+ExPB3P6vfz3d9sILmuYRkfZg3ibRanBw0MfGxvLuBlC+Ueu88+D738+lKyIiiczsYXcfjHtMO3zrcOON8Tt0FfhFpN2oqmcN3GFWycfk1q2wqu6lcBGR1qCRfxVXXlke+N0V+EWkvWnkn2ByEpYsCRZxC155BebPz69PIiJp0cg/xqWXBkG+EPh//vNgtK/ALyKdQiP/iF27YPny6ftf+Qpce21u3RERyYyCP8Go/jOfgdtvn27btw/eHlfUQkSkA3T9tM9PfhIs6BYC/3XXBR8GCvwi0sm6duQ/OQnLlsGhcN/xiSfC44/D3Ln59ktEpBm6cuT/3e8Gi7eFwP/ggzA+HhP4R0ehvz/4atDfH9wXEekAXTXyn5gIYnjBunVw/fUJF4+OBierT05OP3n9+uD20FCW3RQRyVxXjPzd4W/+pjjw/+EPFQI/wPDwdOAvmJwM2kVE2lzHB//77gtmbX70o+D+5s3Bh8HixVWeuHt3fe0iIm2k46d9CnX1ly+HnTvhqKNqfGJvbzDVE9cuItLmOnvkPzrKbxev5lHey1NT/Rz1T3Us2G7aBPPmFbfNmxe0i4i0uc4d+YcLticfWbClvgXbwjXDw8FUT29vEPi12CsiHaBzD3Pp74+ftunrC+o4iIh0uMwOczGz/2lm/2Zmj5jZ7WZ2bOSxS8xs3MyeMLNPRNpXh23jZnZxI+9fkRZsRUQSNTrnvxV4j7ufDPwOuATAzFYA5wAnAauBK81sdnio+xXAJ4EVwOfDa9OXtDA70wVbbfgSkQ7SUPB3939x9zfDuw8BS8PbZwG3uvtr7v40wWHtp4Y/4+7+lLu/DtwaXpu+NBdsCxu+JiaCPNHChi99AIhIm0oz22cd8OPw9hLgmchje8K2pPb0DQ0FSf19fTOtTXEAAAMjSURBVMHBu319wf2ZLNhqw5eIdJiq2T5mdi8QV+Ny2N3vCK8ZBt4EUh0Km9l6YD1A70yma4aG0snO0fqBiHSYqsHf3SueVmtmXwT+A/BRn04d2gssi1y2NGyjQnvce28GNkOQ7VOtr5nRhi8R6TCNZvusBr4J/LW7R+dFtgDnmNlRZrYcGAB+CfwKGDCz5WY2l2BReEsjfWgKbfgSkQ7T6Cav7wFHAVvNDOAhd9/g7o+Z2W3A4wTTQRe4+2EAM7sQuAeYDdzg7o812IfsacOXiHSYzt3kJSLS5TLb5CUiIu1JwV9EpAsp+IuIdCEFfxGRLqTgLyLShdom28fMDhBU5W8FC4CDeXeihejvUUx/j2L6exRr5t+jz90Xxj3QNsG/lZjZWFL6VDfS36OY/h7F9Pco1ip/D037iIh0IQV/EZEupOA/M5vz7kCL0d+jmP4exfT3KNYSfw/N+YuIdCGN/EVEupCC/wxVOry+G5nZZ83sMTObMrPcMxnyYGarzewJMxs3s4vz7k/ezOwGM9tvZjvy7kvezGyZmd1nZo+H/04uyrtPCv4zF3t4fRfbAXwaeCDvjuTBzGYDVwCfBFYAnzezFfn2KnffB1bn3YkW8Sbw9+6+AjgNuCDv/z8U/GeowuH1Xcndd7r7E3n3I0enAuPu/pS7vw7cCpyVc59y5e4PAIfy7kcrcPd97v7r8PbLwE6yOr+8Rgr+6YgeXi/daQnwTOT+HnL+xy2tycz6gb8EfpFnPxo9yauj5Xl4fSuq5e8hIsnM7BjgR8A33P2lPPui4F/BDA+v71jV/h5dbi+wLHJ/adgmAoCZzSEI/KPu/s9590fTPjNU4fB66U6/AgbMbLmZzQXOAbbk3CdpERYccn49sNPdL827P6Dg34jvAW8lOLx+u5ldnXeH8mRmnzKzPcAHgDvN7J68+9RM4eL/hcA9BIt5t7n7Y/n2Kl9mdgvwIPBuM9tjZl/Ou085Oh04FzgzjBfbzWxNnh3SDl8RkS6kkb+ISBdS8BcR6UIK/iIiXUjBX0SkCyn4i4h0IQV/EZEupOAvItKFFPxFRLrQ/wcDt9V/m+q3ogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keWIBW2dK8Mc"
      },
      "source": [
        "# Explicación relacionada a la implementación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6UZ2nHbOXTY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsMcqqG0LDi2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y02UV9RsLE38"
      },
      "source": [
        "# Observación de ajuste de parametros -- Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSz_fhSPLXX2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}